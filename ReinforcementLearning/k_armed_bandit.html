<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Shilpa Musale</title>
        <link rel="icon" type="image/x-icon" href="../assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="../css/styles.css" rel="stylesheet" />
    </head>
    
    <body>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="../index.html">Shilpa Musale (Ishi)</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="../index.html">Home</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="../about.html">About</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        
        <!-- Page Header-->
        <header class="masthead" style="background-image: url('../assets/img/home-bg.jpg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="post-heading">
                            <h1>K-Armed Bandits in Action: Concepts, Code, and Practical Implementation</h1>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Post Content-->
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5">
                <!-- Left Sidebar Navigation -->
                <div class="col-md-3">
                    <nav id="toc" class="sticky-top">
                        <h3>Related Articles</h3>
                        <ul class="nav flex-column">
                            <!-- <li class="nav-item"><a class="nav-link" href="#introduction">Introduction to Reinforcement Learning</a></li> -->
                            <li class="nav-item"><a class="nav-link" href="Intro_rl.html">Introduction to Reinforcement Learning</a></li>
                            <li class="nav-item"><a class="nav-link" href="#reaching-stars">Markov Decision Process (MDP)</a></li>
                        </ul>
                    </nav>
                </div>
                <!-- Blog Post Content -->
                <div class="col-md-9">
                    <article class="mb-4">
                        <div class="container" id="section1"> 
                            
                                <!-- Section 1 -->
                                <h1  class="decorative-heading">K-Armed Bandits in Action: Introduction</h1>
                                <p><h4>What is the K-Armed Bandit Problem?</h4>
                                    Picture this: Youâ€™ve just entered a flashy casino with rows of slot machines gleaming under neon lights. Youâ€™re feeling lucky, but hereâ€™s the twistâ€”these arenâ€™t ordinary slot machines. Each one has its own mysterious payout rate, and you have no clue which ones are jackpot kings or total duds.
                                </p>
                                <p><b>Your mission?</b><br/>ull those levers, figure out which machines are worth your time, and rake in the rewards before your budget runs out. But hereâ€™s the catch:</p>
                                <p>Now, youâ€™re faced with a tricky decision every time you pull a lever:
                                    <li>You donâ€™t know which machine is the goldmine.</li>
                                    <li>Youâ€™ve only got so many chances to find out.</li><br>
                                    Welcome to the K-Armed Bandit Problem, where every pull is a gamble, and every choice is a test of your decision-making skills.
                                    </p>
                                <h6>Why Is It Called a "Bandit" Problem?</h6>
                                <p>Itâ€™s not because these slot machines are out to rob you blind (though they might feel like it). The name comes from the old-school nickname for slot machinesâ€”"one-armed bandits." In this problem, youâ€™re not dealing with just one greedy bandit; youâ€™re up against K sneaky bandits, all vying for your attention (and your metaphorical quarters).
                                <p><h6>The Eternal Struggle: To Explore or Exploit?</h6>
                                    <p>Every time you approach a bandit, you face a dilemma:</p>
                                    
                                    <li>Do you explore? Try a new machine and gather information, hoping itâ€™ll pay off big.</li>
                                    <li>Or do you exploit? Stick with the machine thatâ€™s already been good to you and keep milking those payouts.</li><br>
                                    Too much exploration, and youâ€™ll waste your budget on bad machines. Too much exploitation, and you might miss out on discovering a hidden jackpot. Itâ€™s the ultimate balancing actâ€”kind of like choosing between trying that new trendy restaurant or sticking to your favorite pizza joint.
                                </p>
                                <p>
                                    <h6>Real-Life Bandit Scenarios</h6>
                                    <p>Believe it or not, this isnâ€™t just about slot machines. The K-Armed Bandit Problem pops up all over the place:</p>
                                    <li><b>Online Ads:</b> Should Google show you Ad A (tested and true) or Ad B (a shiny new option)?</li>
                                    <li><b>Medical Trials:</b> Which experimental drug should doctors give to patients to maximize survival rates?</li>
                                    <li><b>Game Design:</b> Which loot box mechanics keep players engaged? Experiment to find the sweet spot without boring your audience.</li><br>
                                    In each case, the same question looms: How do you balance testing new options with sticking to the winners?
                                </p>
                                <p><h6>Why It Matters in RL</h6>
                                    <p>The K-Armed Bandit Problem is like the appetizer to the Reinforcement Learning feast. Itâ€™s simple enough to wrap your head around but juicy enough to teach you the all-important exploration vs. exploitation trade-off. Think of it as RLâ€™s version of training wheels.</p>
                                    <p>So, the next time you face a decision between sticking with what you know or taking a leap of faith, rememberâ€”youâ€™re living the K-Armed Bandit Problem. Just pray youâ€™re pulling the right lever. ðŸŽ°ðŸ’°</p>
                                    <p>Ready to roll the dice and dive deeper into solving this? Letâ€™s go! ðŸš€âœ¨</p>
                                </p>
                                <h4>A k-armed bandit problem : Math</h4><br>
                                <h6>1. Action</h6>
                                <p>The value of an action Q<sub>*</sub>(a) is defined as the expected reward received when selecting that action:<br>
                                    
                                    <p>Q<sub>*</sub>(a) = E[R<sub>t</sub> âˆ£ A<sub>t</sub> = a]</p>
                                    
                                    Where:
                                    <li>R<sub>t</sub> : Reward received at time t</li>
                                    <li>A<sub>t</sub> : Action taken at time t</li>
                                </p>
                                <p>If you knew the exact value of each action, solving the problem would be easyâ€”just pick the action with the highest value. However, since these values are unknown, you must estimate them.</p>
                                <h6>2. Estimating Action Values</h6>
                                <p>
                                    <b>Observed Average:</b>The value of an action can be estimated by averaging the rewards obtained from selecting that action:
                                    <p>Q<sub>*</sub>(a) = SumÂ ofÂ rewardsÂ whenÂ â€™aâ€™Â isÂ takenÂ priorÂ toÂ â€™tâ€™
                                                            / Number of times 'a' was taken prior to 't'
                                    <p>If the denominator is 0 (i.e., the action hasnâ€™t been taken yet), we assign Q<sub>*</sub>(a) a default value, such as 0.</p>  â€‹
                                <h6>3. Law of Large Numbers:</h6>
                                <p>By the law of large numbers, the observed average Q<sub>t</sub>(a) converges to the true action value 
                                    Q<sub>*</sub>(a) as the number of observations increases. This principle explains why, over time, 
                                    random fluctuations in rewards average out, resulting in a more accurate estimate of the true value.</p>
                                <p>Example:
                                    <ul><li>Imagine estimating the average score of a basketball player:

                                    <ul><br><li>True average Q<sub>*</sub>(a): The playerâ€™s true average score is 20 points/game (unknown to you).</li>
                                        <li>Observed averageObserved average Q<sub>t</sub>(a): 
                                            <ul><li>After 1 game: Score = 22, Estimate = 22.</li>
                                            <li>After 10 games: Scores = [22, 18, 20, 25, 15, 19, 21, 23, 20, 18], Sample average = 20.1.</li></ul>
                                        </li></ul><br>
                                    </li>
                                    <li>As the number of observations increases, the sample mean approaches the true average.</li>
                                    </ul>
                                </p>
                                
                                <h4>Finding the Balance: The Art of Decision-Making in Exploration and Exploitation</h4>
                                <p>Balancing exploration and exploitation in the K-Armed Bandit problem isnâ€™t just trickyâ€”itâ€™s an art form. Itâ€™s like trying to decide whether to stick with your favorite pizza joint (you know itâ€™s good) or venture out to try that new sushi place that might blow your mindâ€”or ruin your evening.</p>
                                <p>While there are fancy, sophisticated methods to handle this trade-off, many of them assume that the world is perfect: rewards donâ€™t change over time (stationary distributions) and you magically know things in advance (prior knowledge). But in real life, nothing is that simple. Things change, surprises happen, and your strategy needs to be flexible enough to handle the chaos.</p>
                                <p>This makes finding that sweet spot between playing it safe (exploitation) and rolling the dice (exploration) a tough but critical challenge. Do too much exploring, and youâ€™ll waste resources. Exploit too soon, and you might miss out on something better.</p>
                                <p>But donâ€™t worry, this isnâ€™t the end of the roadâ€”itâ€™s just the beginning of an exciting journey. In the next section, weâ€™ll dive into Methods for Balancing Exploration and Exploitation, exploring practical strategies that help agents make smarter decisions. Think of it as learning to juggle curiosity and confidence like a pro. So, grab your metaphorical juggling balls (or levers), and letâ€™s uncover the secrets to mastering this balancing act! ðŸŽ­ðŸŽ°</p>
                                <div class="navigation">                                    
                                    <a href="./k_armed_bandit_section2.html" class="btn-nav" title="Go to the next section">Next Section</a>
                                </div> 
                                                        
                        </div>                        
                        
                    </article>
                </div>
                           
        
        <!-- Footer-->
        <footer class="border-top">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <ul class="list-inline text-center">
                            <li class="list-inline-item">
                                <a href="https://www.linkedin.com/in/shilpamusale/" target="_blank">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-linkedin-in fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            
                            <li class="list-inline-item">
                                <a href="https://github.com/ishi3012">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li class="list-inline-item">
                                <a href="mailto:ishishiv3012@gmail.com">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                        </ul>
                        <div class="small text-center text-muted fst-italic">Copyright &copy; The Code Diary 2025</div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
